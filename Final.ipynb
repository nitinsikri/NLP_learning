{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Machine Learning Classifiers: Building a basic Random Forest model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in & clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body_len</th>\n",
       "      <th>punct%</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>8094</th>\n",
       "      <th>8095</th>\n",
       "      <th>8096</th>\n",
       "      <th>8097</th>\n",
       "      <th>8098</th>\n",
       "      <th>8099</th>\n",
       "      <th>8100</th>\n",
       "      <th>8101</th>\n",
       "      <th>8102</th>\n",
       "      <th>8103</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>135</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 8106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   body_len  punct%    0    1    2    3    4    5    6    7  ...   8094  8095  \\\n",
       "0       128     4.7  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0   \n",
       "1        49     4.1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0   \n",
       "2        62     3.2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0   \n",
       "3        28     7.1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0   \n",
       "4       135     4.4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0   \n",
       "\n",
       "   8096  8097  8098  8099  8100  8101  8102  8103  \n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 8106 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import string\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "ps = nltk.PorterStemmer()\n",
    "\n",
    "data = pd.read_csv(\"SMSSpamCollection.tsv\", sep='\\t')\n",
    "data.columns = ['label', 'body_text']\n",
    "\n",
    "def count_punct(text):\n",
    "    count = sum([1 for char in text if char in string.punctuation])\n",
    "    return round(count/(len(text) - text.count(\" \")), 3)*100\n",
    "\n",
    "data['body_len'] = data['body_text'].apply(lambda x: len(x) - x.count(\" \"))\n",
    "data['punct%'] = data['body_text'].apply(lambda x: count_punct(x))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = \"\".join([word.lower() for word in text if word not in string.punctuation])\n",
    "    tokens = re.split('\\W+', text)\n",
    "    text = [ps.stem(word) for word in tokens if word not in stopwords]\n",
    "    return text\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(analyzer=clean_text)\n",
    "X_tfidf = tfidf_vect.fit_transform(data['body_text'])\n",
    "X_tfidf_feat = pd.concat([data['body_len'],data['punct%'],pd.DataFrame(X_tfidf.toarray())], axis=1)\n",
    "\n",
    "X_features = pd.concat([data['body_len'], data['punct%'], pd.DataFrame(X_tfidf.toarray())], axis=1)\n",
    "X_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__abstractmethods__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_abc_cache', '_abc_negative_cache', '_abc_negative_cache_version', '_abc_registry', '_estimator_type', '_get_param_names', '_make_estimator', '_set_oob_score', '_validate_X_predict', '_validate_estimator', '_validate_y_class_weight', 'apply', 'decision_path', 'feature_importances_', 'fit', 'get_params', 'predict', 'predict_log_proba', 'predict_proba', 'score', 'set_params']\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(dir(RandomForestClassifier))\n",
    "print(RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore RandomForestClassifier through Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96947935, 0.97307002, 0.97394429, 0.96675651, 0.97214735])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_jobs=-1)\n",
    "k_fold = KFold(n_splits=5)\n",
    "cross_val_score(rf, X_features, data['label'], cv=k_fold, scoring='accuracy', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore RandomForestClassifier through Holdout Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4453\n",
      "1114\n",
      "5567\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X_features,data['label'],test_size=0.2)\n",
    "print(len(X_train))\n",
    "print(len(X_test))\n",
    "print(len(X_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=50,max_depth=20,n_jobs=1)\n",
    "rf_model = rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07428093, 0.00490723, 0.00019022, ..., 0.00039936, 0.        ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.07221251664413995, 'body_len'),\n",
       " (0.07025612911752044, 7350),\n",
       " (0.03687599228705966, 4796),\n",
       " (0.03518843291004981, 2031),\n",
       " (0.03197579269485929, 1803),\n",
       " (0.025831203389402334, 3134),\n",
       " (0.018301001942004097, 5988),\n",
       " (0.017960804132131705, 6285),\n",
       " (0.015037661564691981, 5724),\n",
       " (0.014337512949376607, 6746)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(rf_model.feature_importances_,X_train.columns),reverse=True)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf_model.predict(X_test)\n",
    "precision, recall, fscore, support = score(y_test, y_pred, pos_label='spam', average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.0 / Recall: 0.657 / Accuracy: 0.959\n"
     ]
    }
   ],
   "source": [
    "print('Precision: {} / Recall: {} / Accuracy: {}'.format(round(precision, 3),\n",
    "                                                        round(recall, 3),\n",
    "                                                        round((y_pred==y_test).sum() / len(y_pred),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build our own Grid-search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Grid-search:** Exhaustively search all parameter combinations in a given grid to determine the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_RF(n_est,depth):\n",
    "    rf = RandomForestClassifier(n_estimators=n_est,max_depth=depth,n_jobs=-1)\n",
    "    rf_model = rf.fit(X_train,y_train)\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "    precision, recall, fscore, support = score(y_test, y_pred, pos_label='spam', average='binary')\n",
    "    print('Est :{}/ Depth: {},-------Precesion: {}/ Recall: {}/ Accuracy: {}'.format(n_est,depth,round(precision,3),round(recall,3),\n",
    "                                                                                    round((y_pred==y_test).sum()/len(y_pred),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Est :10/ Depth: 10,-------Precesion: 1.0/ Recall: 0.313/ Accuracy: 0.917\n",
      "Est :10/ Depth: 20,-------Precesion: 1.0/ Recall: 0.619/ Accuracy: 0.954\n",
      "Est :10/ Depth: 30,-------Precesion: 1.0/ Recall: 0.739/ Accuracy: 0.969\n",
      "Est :10/ Depth: None,-------Precesion: 0.991/ Recall: 0.791/ Accuracy: 0.974\n",
      "Est :50/ Depth: 10,-------Precesion: 1.0/ Recall: 0.269/ Accuracy: 0.912\n",
      "Est :50/ Depth: 20,-------Precesion: 1.0/ Recall: 0.597/ Accuracy: 0.952\n",
      "Est :50/ Depth: 30,-------Precesion: 1.0/ Recall: 0.754/ Accuracy: 0.97\n",
      "Est :50/ Depth: None,-------Precesion: 1.0/ Recall: 0.858/ Accuracy: 0.983\n",
      "Est :100/ Depth: 10,-------Precesion: 1.0/ Recall: 0.306/ Accuracy: 0.917\n",
      "Est :100/ Depth: 20,-------Precesion: 1.0/ Recall: 0.567/ Accuracy: 0.948\n",
      "Est :100/ Depth: 30,-------Precesion: 1.0/ Recall: 0.761/ Accuracy: 0.971\n",
      "Est :100/ Depth: None,-------Precesion: 0.991/ Recall: 0.858/ Accuracy: 0.982\n"
     ]
    }
   ],
   "source": [
    "for n_est in [10,50,100]:\n",
    "    for depth in [10,20,30,None]:\n",
    "        train_RF(n_est,depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Machine Learning Classifiers: Evaluate Random Forest with GridSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Grid-search:**: Exhaustively search all parameter combinations in a given grid to determine the best model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross-validation**: Divide a dataset into k subsets and repeat the holdout method k times where a different subset is used \n",
    "as the holdout set in each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>64.443323</td>\n",
       "      <td>0.793377</td>\n",
       "      <td>0.708498</td>\n",
       "      <td>0.104827</td>\n",
       "      <td>90</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 300}</td>\n",
       "      <td>0.978475</td>\n",
       "      <td>0.977538</td>\n",
       "      <td>0.974843</td>\n",
       "      <td>...</td>\n",
       "      <td>0.974672</td>\n",
       "      <td>0.003794</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999326</td>\n",
       "      <td>0.999102</td>\n",
       "      <td>0.999102</td>\n",
       "      <td>0.999775</td>\n",
       "      <td>0.999326</td>\n",
       "      <td>0.999326</td>\n",
       "      <td>0.000246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>50.151165</td>\n",
       "      <td>0.911049</td>\n",
       "      <td>0.483887</td>\n",
       "      <td>0.023117</td>\n",
       "      <td>None</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 300}</td>\n",
       "      <td>0.979372</td>\n",
       "      <td>0.975741</td>\n",
       "      <td>0.974843</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973594</td>\n",
       "      <td>0.004053</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>33.344873</td>\n",
       "      <td>2.530221</td>\n",
       "      <td>0.464649</td>\n",
       "      <td>0.094898</td>\n",
       "      <td>None</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 150}</td>\n",
       "      <td>0.975785</td>\n",
       "      <td>0.977538</td>\n",
       "      <td>0.973944</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973415</td>\n",
       "      <td>0.003396</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50.365459</td>\n",
       "      <td>1.139707</td>\n",
       "      <td>0.584306</td>\n",
       "      <td>0.038363</td>\n",
       "      <td>60</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 60, 'n_estimators': 300}</td>\n",
       "      <td>0.977578</td>\n",
       "      <td>0.973046</td>\n",
       "      <td>0.973944</td>\n",
       "      <td>...</td>\n",
       "      <td>0.972876</td>\n",
       "      <td>0.002988</td>\n",
       "      <td>4</td>\n",
       "      <td>0.994385</td>\n",
       "      <td>0.992366</td>\n",
       "      <td>0.995510</td>\n",
       "      <td>0.993938</td>\n",
       "      <td>0.992366</td>\n",
       "      <td>0.993713</td>\n",
       "      <td>0.001213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>32.434976</td>\n",
       "      <td>1.207455</td>\n",
       "      <td>0.479401</td>\n",
       "      <td>0.050167</td>\n",
       "      <td>90</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 150}</td>\n",
       "      <td>0.976682</td>\n",
       "      <td>0.975741</td>\n",
       "      <td>0.973944</td>\n",
       "      <td>...</td>\n",
       "      <td>0.972517</td>\n",
       "      <td>0.003804</td>\n",
       "      <td>5</td>\n",
       "      <td>0.999326</td>\n",
       "      <td>0.998428</td>\n",
       "      <td>0.999102</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999102</td>\n",
       "      <td>0.999192</td>\n",
       "      <td>0.000504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "8       64.443323      0.793377         0.708498        0.104827   \n",
       "11      50.151165      0.911049         0.483887        0.023117   \n",
       "10      33.344873      2.530221         0.464649        0.094898   \n",
       "5       50.365459      1.139707         0.584306        0.038363   \n",
       "7       32.434976      1.207455         0.479401        0.050167   \n",
       "\n",
       "   param_max_depth param_n_estimators  \\\n",
       "8               90                300   \n",
       "11            None                300   \n",
       "10            None                150   \n",
       "5               60                300   \n",
       "7               90                150   \n",
       "\n",
       "                                      params  split0_test_score  \\\n",
       "8     {'max_depth': 90, 'n_estimators': 300}           0.978475   \n",
       "11  {'max_depth': None, 'n_estimators': 300}           0.979372   \n",
       "10  {'max_depth': None, 'n_estimators': 150}           0.975785   \n",
       "5     {'max_depth': 60, 'n_estimators': 300}           0.977578   \n",
       "7     {'max_depth': 90, 'n_estimators': 150}           0.976682   \n",
       "\n",
       "    split1_test_score  split2_test_score       ...         mean_test_score  \\\n",
       "8            0.977538           0.974843       ...                0.974672   \n",
       "11           0.975741           0.974843       ...                0.973594   \n",
       "10           0.977538           0.973944       ...                0.973415   \n",
       "5            0.973046           0.973944       ...                0.972876   \n",
       "7            0.975741           0.973944       ...                0.972517   \n",
       "\n",
       "    std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "8         0.003794                1            0.999326            0.999102   \n",
       "11        0.004053                2            1.000000            1.000000   \n",
       "10        0.003396                3            1.000000            1.000000   \n",
       "5         0.002988                4            0.994385            0.992366   \n",
       "7         0.003804                5            0.999326            0.998428   \n",
       "\n",
       "    split2_train_score  split3_train_score  split4_train_score  \\\n",
       "8             0.999102            0.999775            0.999326   \n",
       "11            1.000000            1.000000            1.000000   \n",
       "10            1.000000            1.000000            1.000000   \n",
       "5             0.995510            0.993938            0.992366   \n",
       "7             0.999102            1.000000            0.999102   \n",
       "\n",
       "    mean_train_score  std_train_score  \n",
       "8           0.999326         0.000246  \n",
       "11          1.000000         0.000000  \n",
       "10          1.000000         0.000000  \n",
       "5           0.993713         0.001213  \n",
       "7           0.999192         0.000504  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "param = {'n_estimators': [10, 150, 300],\n",
    "        'max_depth': [30, 60, 90, None]}\n",
    "\n",
    "gs = GridSearchCV(rf, param, cv=5, n_jobs=-1)\n",
    "gs_fit = gs.fit(x_tifdf_feat, data['label'])\n",
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending=False)[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Machine Learning Classifiers: Explore Gradient Boosting model with grid-search\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Grid-search:** Exhaustively search all parameter combinations in a given grid to determine the best model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore GradientBoostingClassifier Attributes & Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_SUPPORTED_LOSS', '__abstractmethods__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_abc_cache', '_abc_negative_cache', '_abc_negative_cache_version', '_abc_registry', '_check_initialized', '_check_params', '_clear_state', '_decision_function', '_estimator_type', '_fit_stage', '_fit_stages', '_get_param_names', '_init_decision_function', '_init_state', '_is_initialized', '_make_estimator', '_resize_state', '_staged_decision_function', '_validate_estimator', '_validate_y', 'apply', 'decision_function', 'feature_importances_', 'fit', 'get_params', 'n_features', 'predict', 'predict_log_proba', 'predict_proba', 'score', 'set_params', 'staged_decision_function', 'staged_predict', 'staged_predict_proba']\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(dir(GradientBoostingClassifier))\n",
    "print(GradientBoostingClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build our own Grid-search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_GB(est, max_depth, lr):\n",
    "    gb = GradientBoostingClassifier(n_estimators=est, max_depth=max_depth, learning_rate=lr)\n",
    "    gb_model = gb.fit(X_train, y_train)\n",
    "    y_pred = gb_model.predict(X_test)\n",
    "    precision, recall, fscore, train_support = score(y_test, y_pred, pos_label='spam', average='binary')\n",
    "    print('Est: {} / Depth: {} / LR: {} ---- Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "        est, max_depth, lr, round(precision, 3), round(recall, 3), \n",
    "        round((y_pred==y_test).sum()/len(y_pred), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Est: 50 / Depth: 3 / LR: 0.01 ---- Precision: 0.0 / Recall: 0.0 / Accuracy: 0.872\n",
      "Est: 50 / Depth: 3 / LR: 0.1 ---- Precision: 0.971 / Recall: 0.699 / Accuracy: 0.959\n",
      "Est: 50 / Depth: 3 / LR: 1 ---- Precision: 0.921 / Recall: 0.811 / Accuracy: 0.967\n",
      "Est: 50 / Depth: 7 / LR: 0.01 ---- Precision: 1.0 / Recall: 0.014 / Accuracy: 0.873\n",
      "Est: 50 / Depth: 7 / LR: 0.1 ---- Precision: 0.934 / Recall: 0.797 / Accuracy: 0.967\n",
      "Est: 50 / Depth: 7 / LR: 1 ---- Precision: 0.901 / Recall: 0.825 / Accuracy: 0.966\n",
      "Est: 50 / Depth: 11 / LR: 0.01 ---- Precision: 1.0 / Recall: 0.007 / Accuracy: 0.873\n",
      "Est: 50 / Depth: 11 / LR: 0.1 ---- Precision: 0.913 / Recall: 0.804 / Accuracy: 0.965\n",
      "Est: 50 / Depth: 11 / LR: 1 ---- Precision: 0.929 / Recall: 0.818 / Accuracy: 0.969\n",
      "Est: 50 / Depth: 15 / LR: 0.01 ---- Precision: 0.0 / Recall: 0.0 / Accuracy: 0.871\n",
      "Est: 50 / Depth: 15 / LR: 0.1 ---- Precision: 0.906 / Recall: 0.804 / Accuracy: 0.964\n",
      "Est: 50 / Depth: 15 / LR: 1 ---- Precision: 0.908 / Recall: 0.825 / Accuracy: 0.967\n",
      "Est: 100 / Depth: 3 / LR: 0.01 ---- Precision: 0.96 / Recall: 0.503 / Accuracy: 0.934\n",
      "Est: 100 / Depth: 3 / LR: 0.1 ---- Precision: 0.982 / Recall: 0.783 / Accuracy: 0.97\n",
      "Est: 100 / Depth: 3 / LR: 1 ---- Precision: 0.95 / Recall: 0.797 / Accuracy: 0.969\n",
      "Est: 100 / Depth: 7 / LR: 0.01 ---- Precision: 0.97 / Recall: 0.685 / Accuracy: 0.957\n",
      "Est: 100 / Depth: 7 / LR: 0.1 ---- Precision: 0.943 / Recall: 0.811 / Accuracy: 0.969\n",
      "Est: 100 / Depth: 7 / LR: 1 ---- Precision: 0.915 / Recall: 0.825 / Accuracy: 0.968\n",
      "Est: 100 / Depth: 11 / LR: 0.01 ---- Precision: 0.924 / Recall: 0.762 / Accuracy: 0.961\n",
      "Est: 100 / Depth: 11 / LR: 0.1 ---- Precision: 0.937 / Recall: 0.825 / Accuracy: 0.97\n",
      "Est: 100 / Depth: 11 / LR: 1 ---- Precision: 0.888 / Recall: 0.832 / Accuracy: 0.965\n",
      "Est: 100 / Depth: 15 / LR: 0.01 ---- Precision: 0.917 / Recall: 0.769 / Accuracy: 0.961\n",
      "Est: 100 / Depth: 15 / LR: 0.1 ---- Precision: 0.922 / Recall: 0.825 / Accuracy: 0.969\n",
      "Est: 100 / Depth: 15 / LR: 1 ---- Precision: 0.898 / Recall: 0.86 / Accuracy: 0.969\n",
      "Est: 150 / Depth: 3 / LR: 0.01 ---- Precision: 0.962 / Recall: 0.538 / Accuracy: 0.938\n",
      "Est: 150 / Depth: 3 / LR: 0.1 ---- Precision: 0.991 / Recall: 0.811 / Accuracy: 0.975\n",
      "Est: 150 / Depth: 3 / LR: 1 ---- Precision: 0.967 / Recall: 0.832 / Accuracy: 0.975\n",
      "Est: 150 / Depth: 7 / LR: 0.01 ---- Precision: 0.954 / Recall: 0.72 / Accuracy: 0.96\n",
      "Est: 150 / Depth: 7 / LR: 0.1 ---- Precision: 0.95 / Recall: 0.804 / Accuracy: 0.969\n",
      "Est: 150 / Depth: 7 / LR: 1 ---- Precision: 0.91 / Recall: 0.853 / Accuracy: 0.97\n",
      "Est: 150 / Depth: 11 / LR: 0.01 ---- Precision: 0.923 / Recall: 0.755 / Accuracy: 0.961\n",
      "Est: 150 / Depth: 11 / LR: 0.1 ---- Precision: 0.929 / Recall: 0.825 / Accuracy: 0.969\n",
      "Est: 150 / Depth: 11 / LR: 1 ---- Precision: 0.914 / Recall: 0.818 / Accuracy: 0.967\n",
      "Est: 150 / Depth: 15 / LR: 0.01 ---- Precision: 0.911 / Recall: 0.783 / Accuracy: 0.962\n",
      "Est: 150 / Depth: 15 / LR: 0.1 ---- Precision: 0.915 / Recall: 0.832 / Accuracy: 0.969\n",
      "Est: 150 / Depth: 15 / LR: 1 ---- Precision: 0.863 / Recall: 0.839 / Accuracy: 0.962\n"
     ]
    }
   ],
   "source": [
    "for n_est in [50, 100, 150]:\n",
    "    for max_depth in [3, 7, 11, 15]:\n",
    "        for lr in [0.01, 0.1, 1]:\n",
    "            train_GB(n_est, max_depth, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier()\n",
    "param = {\n",
    "    'n_estimators': [150], \n",
    "    'max_depth': [15],\n",
    "    'learning_rate': [0.1]\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(gb, param, cv=3, n_jobs=-1)\n",
    "cv_fit = clf.fit(X_tfidf_feat, data['label'])\n",
    "result=pd.DataFrame(cv_fit.cv_results_).sort_values('mean_test_score', ascending=False)[0:5]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
